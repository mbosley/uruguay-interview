# Uruguay Active Listening: AI-Powered Interview Analysis Framework

An advanced AI framework for analyzing citizen consultation interviews at scale, developed for the Uruguay Government's 5-year active listening initiative. This system processes qualitative interviews through sophisticated annotation pipelines, enabling both real-time policy insights and groundbreaking academic research.

## ğŸ¯ Project Overview

This framework addresses the challenge of analyzing 5000+ citizen interviews over 5 years, transforming rich qualitative data into actionable policy insights while preserving the authenticity of citizen voices.

### Key Features

- **Two-Layer Architecture**: Rich qualitative annotations (Layer 1) + Structured quantitative extraction (Layer 2)
- **AI-Powered Annotation**: Advanced LLM-based interview analysis with quality validation
- **Real-time Dashboards**: Executive, researcher, and public-facing insights
- **WhatsApp AI Follow-ups**: Automated conversational engagement with participants
- **Digital Twin Research**: Individual-level political reasoning models
- **Scalable Infrastructure**: Handles 1000+ interviews per month

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- PostgreSQL 13+
- Redis 6+
- Pandoc (for document conversion)

### Installation

```bash
# Clone the repository
git clone https://github.com/mbosley/uruguay-interview.git
cd uruguay-interview

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install in development mode
pip install -e .

# Copy environment variables
cp .env.example .env
# Edit .env with your API keys and configuration
```

### Basic Usage

```bash
# Convert interview documents to text
python scripts/convert_interviews.sh

# Run annotation pipeline on a single interview
uruguay-pipeline --interview data/raw/interviews/interview_001.docx

# Batch process multiple interviews
uruguay-batch --input-dir data/raw/interviews --output-dir data/processed/annotations

# Check annotation quality
uruguay-quality --annotations-dir data/processed/annotations

# Generate dashboards
uruguay-export --type dashboard --output deliverables/government/dashboards
```

## ğŸ“ Project Structure

```
uruguay-interview/
â”œâ”€â”€ config/                 # Configuration files
â”‚   â”œâ”€â”€ prompts/           # AI prompts and schemas
â”‚   â”œâ”€â”€ database/          # Database schemas
â”‚   â””â”€â”€ dashboards/        # Dashboard configurations
â”œâ”€â”€ src/                   # Source code
â”‚   â”œâ”€â”€ pipeline/          # Core annotation pipeline
â”‚   â”œâ”€â”€ analysis/          # Analysis components
â”‚   â”œâ”€â”€ dashboards/        # Dashboard generation
â”‚   â”œâ”€â”€ followup/          # WhatsApp AI system
â”‚   â””â”€â”€ research/          # Academic research components
â”œâ”€â”€ data/                  # Data directory (gitignored)
â”œâ”€â”€ tests/                 # Test suite
â”œâ”€â”€ scripts/               # Operational scripts
â”œâ”€â”€ notebooks/             # Jupyter notebooks
â”œâ”€â”€ docs/                  # Documentation
â””â”€â”€ deliverables/          # Stakeholder outputs
```

## ğŸ”§ Core Components

### 1. Annotation Pipeline

The heart of the system, processing interviews through multiple stages:

```python
from src.pipeline import AnnotationPipeline

pipeline = AnnotationPipeline()
annotation = pipeline.process_interview("path/to/interview.docx")
```

### 2. Quality Assurance

Comprehensive validation to ensure annotation accuracy:

```python
from src.pipeline.quality import QualityValidator

validator = QualityValidator()
quality_report = validator.validate_annotation(annotation)
```

### 3. Dashboard Generation

Real-time insights for different stakeholders:

```python
from src.dashboards import ExecutiveDashboard

dashboard = ExecutiveDashboard()
dashboard.update_with_latest_data()
dashboard.export("deliverables/government/dashboards/executive.html")
```

## ğŸ“Š Data Flow

1. **Input**: Raw interview files (DOCX/ODT)
2. **Processing**: Text extraction â†’ AI annotation â†’ Quality validation
3. **Storage**: Layer 1 (JSON) â†’ Layer 2 (SQL)
4. **Analysis**: Quantitative insights + Qualitative context
5. **Output**: Dashboards, reports, research datasets

## ğŸ›¡ï¸ Security & Privacy

- All interview data is excluded from version control
- Participant identifiers are anonymized
- API keys stored in environment variables
- Encrypted data transmission for WhatsApp integration

## ğŸ“š Documentation

- [Project Roadmap](docs/roadmap/PROJECT_ROADMAP.md)
- [Quantitative Insights Framework](docs/roadmap/QUANTITATIVE_INSIGHTS_FRAMEWORK.md)
- [Technical Architecture](docs/technical/architecture.md)
- [Training Materials](docs/training/)

## ğŸ¤ Contributing

This project follows conventional commit standards. See [CLAUDE.md](CLAUDE.md) for development guidelines.

### Development Setup

```bash
# Install development dependencies
pip install -r requirements-dev.txt

# Set up pre-commit hooks
pre-commit install

# Run tests
pytest

# Run linting
ruff check .
black --check .
```

## ğŸ“ˆ Roadmap

### Phase 1: Foundation (Current)
- âœ… Core pipeline implementation
- âœ… Basic annotation functionality
- ğŸ”„ Quality validation system

### Phase 2: Production Scale
- WhatsApp AI integration
- Advanced dashboards
- Batch processing optimization

### Phase 3: Research Innovation
- Digital twin methodology
- Synthetic survey generation
- Cross-method validation

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Uruguay Government's Presidency Office
- Citizen participants in the active listening initiative
- Research team: Juan Pablo Luna, Mitchell Bosley, and collaborators

## ğŸ“ Contact

For questions about the framework or collaboration opportunities, please open an issue on GitHub.

---

*Building the future of democratic participation through AI-powered citizen listening*